diff --git a/setup.py b/setup.py
index 05735a33..b8abccff 100644
--- a/setup.py
+++ b/setup.py
@@ -18,20 +18,6 @@
     # instead of split
     #   -ltorch_cuda_cu -ltorch_cuda_cpp
     torch_cpp_ext.BUILD_SPLIT_CUDA = False
-
-    if hasattr(torch_cpp_ext, "CUDA_GCC_VERSIONS"):
-        # hack to be able to compile with gcc-8.4.0
-        torch_cpp_ext.CUDA_GCC_VERSIONS["10.2"] = (
-            torch_cpp_ext.MINIMUM_GCC_VERSION,
-            (8, 4, 99),
-        )
-
-    torch_version = torch.__version__.split(".")
-    torch_geq_113 = (
-        int(torch_version[0]) > 1
-        or int(torch_version[0]) == 1
-        and int(torch_version[1]) >= 13
-    )
 except ModuleNotFoundError:
     print("Theseus installation requires torch.")
     sys.exit(1)
@@ -41,7 +27,7 @@ def parse_requirements_file(path):
     with open(path) as f:
         reqs = []
         for line in f:
-            if "functorch" in line and torch_geq_113:
+            if "functorch" in line:
                 # Don't install functorch 0.2.1 if torch 1.13 already
                 # installed
                 continue
